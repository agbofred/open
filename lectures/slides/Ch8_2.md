---
title: "Sorting"
author: Jed Rembold
date: December 3, 2021
slideNumber: true
theme: "python_monokai"
highlightjs-theme: monokai
width: 1920
height: 1200
transition: slide
hash: true
history: false

---


## Announcements
- Be working on Adventure!
	- Reminder to let me know if you are looking for a partner so I can try to match people up. Or feel free to post publically on Discord or Campuswire.
- Lab today on measuring program runtimes
- Polling: [rembold-class.ddns.net](http://rembold-class.ddns.net)


## Review Question
::::::cols
::::col
You want to look for the term `"fish"` in the list to the right. What search method would prove fastest in this specific case?

:::{.poll}
#. Linear Search
#. Binary Search
#. Both would be equal
:::

::::

::::col
```{.python style="max-height:900px"}
list_to_search = [
	"onions",
	"puppies",
	"fish",
	"donkey",
	"carrots",
	"goats",
	"lasagna",
	"sheep",
	"bears",
	"beets",
	"battlestar galactica"
]
```

::::
::::::

<!--
## Linear Search Efficiency
- The running time of the linear search depends on the size of the array
	- That in itself is not really surprising. The running time of most algorithms will depend on the size of the problem to which the algorithm is applied.
- For many applications, it is easy to come up with a numeric value that describes the problem size, commonly called $N$.
	- For most lists, $N$ is simply the length of the array
- In the worst case, when the target value is the last element of the list or does not appear at all, the linear search requires $N$ steps
	- On average, it takes about half that, or $\frac{N}{2}$


## Binary Search Efficiency
- The running time of binary search also depends on the size of the array, but in a very different way
- Each step of the process, the binary search rules out half the remaining options
	- The worst case (which we had earlier!) requires a number of steps equal to however many times we can divide the array in half until we have only a single number left.
	- Mathematically, this looks like
		$$1 = N / \underbrace{2 / 2 / 2 / 2 \cdots / 2}_{k\text{ times}} = \frac{N}{2^k}$$
- We really want to know the number of steps, $k$, so solving for $k$:
$$2^k = N \quad\Rightarrow\quad k = \log_2(N)$$
-->

## Comparing Efficiencies
- The below table illustrates the differences in the number of required steps for the two search algorithms

Problem Size | Linear ($N$) | Binary ($\log_2 N$)
--- | --- | ---
10 | 10 | 3
100 | 100 | 7
1000 | 1000 | 10
1000000 | 1000000 | 20
1000000000 | 1000000000 | 30

- Clearly, for large values, the difference in the number of steps is **enormous**
- At 1 million elements, the binary search is 50,000 times faster!


## Sorting
- Binary search only works on arrays in which the elements are ordered.
	- The process of putting the elements into order is called _sorting_.
- Lots of different sorting algorithms, which can vary substantially in their efficiency.
- From an algorithms view, sorting is probably the most applicable algorithm we'll discuss in this course
	- Organizing data makes it easier to digest that data, whether the data is being digested by other machines or by humans


## Selection Sort
- The easiest sorting algorithm to explain is that of _selection sort_
- Imagine your left hand keeping track of where you were in the array, and your right hand scanning through and finding the next smallest value to move to that location each iteration
```python
def selection_sort(array):
	for lh in range(len(array)):
		rh = lh
		for i in range(lh+1, len(array)):
			if array[i] < array[rh]:
				rh = i
		array[lh], array[rh] = array[rh], array[lh]
```

## Following Selection Sort
```{.python data-line-numbers='1-9|2|3|4|5|4|5|4|5|6|4|5|4|5|4|5|4|5|4|5|6|4|4|7|2|3|4|1-9'}
def selection_sort(array):
	for lh in range(len(array)):
		rh = lh
		for i in range(lh+1, len(array)):
			if array[i] < array[rh]:
				rh = i
		array[lh], array[rh] = array[rh], array[lh]
L = [31, 41, 59, 26, 53, 58, 97, 93, 23, 84]
selection_sort(L)
```

<div class="fig-container" data-file="../images/d3/SelectionSort.html" data-scroll="no", data-style="width:90%; display:inline;"></div>


## Selection Sort Efficiency
- One method to investigate the efficiency would be to time how long different operations took
- For one particular laptop, those times might look like:

Array Size | Running Time (sec) | Increase of
--- | --- | ---
10 | 0.000013 s |
100 | 0.000581 s | 44x
1,000 | 0.0578 s | 99x
10,000 | 5.738 s | 99x
100,000 | 574.2 s | 100x
1,000,000 | 57395 s | 100x

- The time to sort 1 million entries is just under 16 hours!


## Quicker Estimation of Selection Sort Efficiency
- Alternatively, we can estimate the efficiency by counting up how many times the most frequent operation is executed
	- The idea being that all the basic Python operations take around the same amount of time to do
- In selection sort that is the inner `for` loop comparison
	- Checks 10 ($N$) values the first time through
	- Checks 9 ($N-1$) values the second time through
	- Checks 8 ($N-2$) values the third time through, etc
- Can simplify with some series math
$$\displaystyle N + (N-1) + (N-2) + (N-3) + \cdots = \sum_{i=1}^N i = \frac{N\times(N+1)}{2}$$


## Quadratic Growth
::::::cols
::::col
- Like with the run times, we can compare how this value scales with increasing $N$ values in the table to the right
- We see this tracks pretty close to our run time results, so our method of estimating the efficiency must be decent
- Multiplying things out, our efficiency scales as
$$\frac{1}{2}(N^2 + N) \approx N^2$$

::::

::::col

$N$ | $\tfrac{N\times(N+1)}{2}$ | Increase of
--- | --- | ---
10 | 55 | 
100 | 5,050 | 92x
1,000 | 500,500 | 99x
10,000 | 50,005,000 | 100x
100,000 | 5,000,050,000 | 100x

::::
::::::

## Big-O Notation
- The common way to express notational complexity is to use _big-O notation_, introduced by German mathematician Paul Bachmann in 1892
- Big-O notations consists of the letter $\mathcal{O}$ followed by a formula that offers a qualitative assessment of the program running time as a function of the problem size ($N$)
- The complexity of linear search was:
$$\mathcal{O}(N)$$
- The complexity of selection sort was:
$$\mathcal{O}(N^2)$$
- Read aloud, these would be "big-O of $N$" or "big-O of $N^2$"


## Simplifying Big-O
- Big-O just gives a qualitative estimate, so it makes sense to keep the expression on the inside as simple as possible
- When writing big-O expressions, make the following simplifications:
	- Eliminate any constant factors
	- Eliminate any term whose contribution ceases to become significant when $N$ becomes large
- Thus the computational complexity of selection sort is
$$\mathcal{O}(N^2)$$
and **not**
$$\mathcal{O}\left(\frac{N^2 + N}{2}\right)$$


## Deducing complexity from code
- Can often get a feeling for complexity just by looking at the code structure
- Find the section of code that seems to be executed the most
- How many times does that piece of code seem to be executed in comparison to the problem difficulty?
- Loops are often key!
	- Code in a single loop that iterates $N$ times gets executed $N$ times
	- Code in a pair of nested loops that each iterate $N$ times gets executed $N^2$ times


## Understanding Check
What would be the big-O complexity of the below function?

```python
def func(array):
	n = 0
	while n < len(array):
		for i in range(n):
			array[i] = array[n]
		n += 2

```
:::hpoll
#. $\mathcal{O}(N)$
#. $\mathcal{O}(N^2)$
#. $\mathcal{O}(N^{1/2})$
#. $\mathcal{O}(\frac{N^2}{2})$
:::

## A More Efficient Strategy
- As long as arrays are small, selection sort is perfectly workable!
	- Even 10,000 elements get sorted in just over 1 second
- Less attractive to commercial applications with **huge** arrays though
	- Sorting a million values to take over 3 hours?!
- The $\mathcal{O}(N^2)$ complexity does offer a little hope though
	- Sorting twice as many elements takes four times as long = BAD
	- But sorting half as many elements takes only a quarter the time = GOOD!
	- Can we break the array into smaller pieces and just work with those?
