---
title: "#Hashes"
author: Jed Rembold
date: November 12, 2021
slideNumber: true
theme: "python_monokai"
highlightjs-theme: monokai
width: 1920
height: 1200
transition: slide
hash: true
history: false

---


## Announcements
- Keep making progress on Project 4!
- Lab today is about dictionaries
- I think we will **not** have a lab next Friday, but rather I'll just keep things open for last minute Enigma questions
- Polling: [rembold-class.ddns.net](http://rembold-class.ddns.net)

## Review Question {data-notes="Solution: [100,167,173,204]"}
What is the printed value of the below code?
```python
A = [
	{'name': 'Jill',  'weight':125, 'height':62},
	{'name': 'Sam',   'weight':156, 'height':68},
	{'name': 'Bobby', 'weight':173, 'height':72},
]
A.append({'weight':204, 'height':70, 'name':'Jim'})
B= A[1]
B['weight'] = 167
A[0].clear()
print([d.get('weight',100) for d in A])
```


<div class='cols'>
<div class='col poll'>
<ol>
	<li> `[100,156,173,204]`</li>
	<li>`[156,173,204]`</li>
	</ol>
</div>
<div class='col poll'>
<ol style='counter-reset: li 2'>
	<li> `[100,167,173,204]` </li>
	<li>`[125,167,173,204]` </li>
</ol>
</div>
</div>



## Hash Codes, not Browns
- Python has a built-in function called `hash` that takes an object and returns an integer, which is called the _hash code_ for that object
- Hash codes must follow a set of guidelines (or a code of conduct):
	#. The hash code must be relatively easy to compute
	#. The hash code for a particular object must always be the same for a given Python session
	#. If two objects are identical, they must have the same hash code
	#. The hash codes must be distributed as randomly/evenly as possible over the space of possible keys
- Maps using the hashing algorithm use the hash code for a key as a starting point to help find the associated value.


## Bucket Hashing
- One common strategy is to choose a certain number of _buckets_ to make up an array, where each object's hash will place it into a particular bucket
	- Would mean that, having checked a key's hash, you'd know which bucket to look in!
- In practice, the number of buckets is smaller than the number of hash codes, so you need a way to decide on what hash code corresponds to which bucket.
	- Typically done with a remainder operation along the lines of
	```python
	bucket = abs(hash(key)) % num_buckets
	```
- Some buckets will still end up with multiple key-value pairs. These are called _collisions_ and lower the efficiency of the algorithm.
- Since hash codes are spread around equally, each bucket in theory would end up with similar numbers of key-value pairs


## Bucket Hashing Examples
```{.python style='max-height:900px; font-size:0.8em;'}
class Dictionary:
    NBUCKETS = 5

    def __init__(self):
        self.buckets = [ [] for _ in range(Dictionary.NBUCKETS)]

    def get(self, key):
        H = hash(key)
        bucket_id = abs(H) % Dictionary.NBUCKETS
        for pair in self.buckets[bucket_id]:
            if pair[0] == key:
                return pair[1]
        return None

    def put(self, key, value):
        H = hash(key)
        bucket_id = abs(H) % Dictionary.NBUCKETS
        bucket = self.buckets[bucket_id]
        for i in range(len(bucket)):
            if bucket[i][0] == key:
                bucket[i] = (key, value)
                return
        bucket.append((key,value))

    def __repr__(self):
        return repr(self.buckets)
```

## Ultimate Efficiency
- The smaller the number of buckets, the more likely collisions are
- Want to minimize collisions so generally choose a large number of buckets
	- Too many buckets though, and you are just wasting memory with empty lists
- Ratio of number of keys over the number of buckets is called the _load factor_ of a map
	- Generally need a load factor of around 0.7 or lower to get no collisions on average
- If the dictionary grows such that it needs more buckets, the buckets can be redone, in a process called _rehashing_


## Abstract Data Types
- Have looked at compound objects like lists, tuples, dictionaries, and classes individually, but want to start to see how they could be brought together to represent larger data structures
- Types that are defined by their behavior are called _abstract data types_ or _ADT_ s which have the following advantages
	- Simplicity. The internal representation is hidden from the client
	- Flexibility. If the internal representation needs to be changed by the programmer, they can do so without breaking outside compatibility
	- Security. Keeping the internal representation away from clients prevents clients from directly altering values that may cause the type to behave unexpectedly
- Want to start to focus on how we can bring all these ideas together to define our own abstract types


## Token ADT
- I find it helps to think of ADT's as a type which helps to fulfill a particular objective or behavioral goal
- Cast your mind back to our Pig Latin translation program, which had two main pieces
	- `to_pig_latin` which was responsible for taking a phrase and breaking it up into words
	- `word_to_pig_latin` which took a single word and translated into Pig Latin
- The first is an example of something that comes up often in computer science
	- Breaking a larger thing into particular smaller chunks
	- Chunks can really be anything, so the more general term computer scientists use is a _token_

## A Token Scanner
- A type that plucked out individual tokens might be called a _token scanner_
- What would a client want from a token scanner?
	- A way to pass in the necessary input
	- A way to retrieve the next individual token
	- A way to know when there are no more tokens
	- Maybe a way to tailor what tokens are desired
- These requirements help inform what methods should be incorporated into a token scanner class!
	- Still need to determine what internal attributes or method might be needed

## Token Scanner Design
- Frequently, specific wants or objectives make for good methods to include in the token scanner
- Chapter 12 includes an example of a common implementation
- Exports 4 main methods:
	#. `scanner.set_input(str)`
		- Sets the input of the token scanner to the specified string or input stream
	#. `scanner.next_token()`
		- Returns the next token from the stream, or `""` at the end
	#. `scanner.has_more_tokens`
		- Returns `True` if more tokens exist, `False` otherwise
	#. `scanner.ignore_whitespace()`
		- Customization option which tells the scanner to ignore whitespace characters

## Token Scanner Code
```{.python style='max-height:900px; font-size:.7em; font-spacing:2em;' data-line-numbers='7-46|54-59|63-69|71-86|88-94|96-100|104-109'}
# File: tokenscanner.py

"""
This file implements a simple version of a token scanner class.
"""

# A token scanner is an abstract data type that divides a string into
# individual tokens, which are strings of consecutive characters that
# form logical units.  This simplified version recognizes two token types:
#
#   1. A string of consecutive letters and digits
#   2. A single character string
#
# To use this class, you must first create a TokenScanner instance by
# calling its constructor:
#
#     scanner = TokenScanner()
#
# The next step is to call the set_input method to specify the string
# from which tokens are read, as follows:
#
#     scanner.set_input(s)
#
# Once you have initialized the scanner, you can retrieve the next token
# by calling
#
#    token = scanner.next_token()
#
# To determine whether any tokens remain to be read, you can either
# call the predicate method scanner.has_more_tokens() or check to see
# whether next_token returns the empty string.
#
# The following code fragment serves as a pattern for processing each
# token in the string stored in the variable source:
#
#     scanner = TokenScanner(source)
#     while scanner.has_more_tokens():
#         token = scanner.next_token()
#         . . . code to process the token . . .
#
# By default, the TokenScanner class treats whitespace characters
# as operators and returns them as single-character tokens.  You
# can set the token scanner to ignore whitespace characters by
# making the following call:
#
#     scanner.ignore_whitespace()

class TokenScanner:

    """This class implements a simple token scanner."""

# Constructor

    def __init__(self, source=""):
        """
        Creates a new TokenScanner object that scans the specified string.
        """
        self.set_input(source)
        self._ignore_whitespace_flag = False

# Public methods

    def set_input(self, source):
        """
        Resets the input so that it comes from source.
        """
        self._source = source
        self._nch = len(source)
        self._cp = 0

    def next_token(self):
        """
        Returns the next token from this scanner.  If called when no
        tokens are available, next_token returns the empty string.
        """
        if self._ignore_whitespace_flag:
            self._skip_whitespace()
        if self._cp == self._nch:
            return ""
        token = self._source[self._cp]
        self._cp += 1
        if token.isalnum():
            while self._cp < self._nch and self._source[self._cp].isalnum():
                token += self._source[self._cp]
                self._cp += 1
        return token

    def has_more_tokens(self):
        """
        Returns True if there are more tokens for this scanner to read.
        """
        if self._ignore_whitespace_flag:
            self._skip_whitespace()
        return self._cp < self._nch

    def ignore_whitespace(self):
        """
        Tells the scanner to ignore whitespace characters.
        """
        self._ignore_whitespace_flag = True

# Private methods

    def _skip_whitespace(self):
        """
        Skips over any whitespace characters before the next token.
        """
        while self._cp < self._nch and self._source[self._cp].isspace():
            self._cp += 1
```

## Using `TokenScanner`
- Need to initialize the token scanner object
- Generally keep looping as long as there are still tokens
	- Each iteration, get the latest token and then do something with it


## Using `TokenScanner` in `PigLatin`
```{.python style='max-height:900px'}
from tokenscanner import TokenScanner

def to_pig_latin(text):
	translation = ""
	scanner = TokenScanner()
	scanner.set_input(text)
	while scanner.has_more_tokens():
		token = scanner.next_token()
		if token.isalpha():
			token = word_to_pig_latin(token)
		translation += token
	return translation
```
